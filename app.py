# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pkMpAZrtTGAqGjvKII_T2oqWs5Njc2Wo
"""

import streamlit as st
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import tempfile
import os
from gtts import gTTS
from moviepy.editor import ImageSequenceClip, AudioFileClip, CompositeAudioClip
import time

# Page configuration
st.set_page_config(
    page_title="AI Scene Video Generator",
    page_icon="üé¨",
    layout="centered"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
    .stTextArea textarea {
        background-color: rgba(255, 255, 255, 0.9);
    }
    h1 {
        color: white;
        text-align: center;
    }
    .stButton button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: bold;
        border: none;
        padding: 0.5rem 2rem;
        border-radius: 10px;
    }
    </style>
""", unsafe_allow_html=True)

# Title
st.markdown("# üé¨ AI Scene Video Generator")
st.markdown("### Create a 15-second video from three scene descriptions")

# Initialize session state
if 'generated_video' not in st.session_state:
    st.session_state.generated_video = None

def generate_image_from_text(text, width=800, height=600):
    """Generate a simple visual representation using Pillow"""
    # Create image with gradient background
    img = Image.new('RGB', (width, height))
    draw = ImageDraw.Draw(img)

    # Create gradient background based on text hash
    hash_val = hash(text) % 360
    for y in range(height):
        ratio = y / height
        r = int(100 + ratio * 100 + (hash_val % 55))
        g = int(80 + ratio * 120 + ((hash_val * 2) % 55))
        b = int(150 + ratio * 80 + ((hash_val * 3) % 55))
        draw.rectangle([(0, y), (width, y+1)], fill=(r, g, b))

    # Add geometric shapes based on keywords
    keywords = text.lower().split()
    if any(word in keywords for word in ['mountain', 'peak', 'hill']):
        # Draw mountains
        points = [(100, 500), (300, 200), (500, 500)]
        draw.polygon(points, fill=(60, 60, 80))
        points = [(300, 500), (500, 150), (700, 500)]
        draw.polygon(points, fill=(80, 80, 100))

    if any(word in keywords for word in ['sun', 'sunset', 'sunrise']):
        # Draw sun
        draw.ellipse([600, 100, 700, 200], fill=(255, 200, 100))

    if any(word in keywords for word in ['ocean', 'sea', 'water', 'beach']):
        # Draw waves
        for i in range(5):
            y_pos = 400 + i * 30
            draw.ellipse([0, y_pos, 200, y_pos + 40], fill=(100, 150, 200))
            draw.ellipse([200, y_pos + 10, 400, y_pos + 50], fill=(120, 170, 220))
            draw.ellipse([400, y_pos, 600, y_pos + 40], fill=(100, 150, 200))
            draw.ellipse([600, y_pos + 10, 800, y_pos + 50], fill=(120, 170, 220))

    if any(word in keywords for word in ['forest', 'tree', 'woods']):
        # Draw trees
        for i in range(6):
            x = 50 + i * 130
            draw.rectangle([x+20, 350, x+40, 500], fill=(101, 67, 33))
            draw.ellipse([x-20, 280, x+80, 380], fill=(34, 139, 34))

    if any(word in keywords for word in ['city', 'building', 'urban']):
        # Draw buildings
        for i in range(5):
            x = 50 + i * 150
            h = 200 + (hash(text + str(i)) % 200)
            draw.rectangle([x, 600-h, x+100, 600], fill=(80, 80, 90))
            # Windows
            for row in range(int(h/40)):
                for col in range(3):
                    wx = x + 15 + col * 30
                    wy = 600 - h + 20 + row * 40
                    draw.rectangle([wx, wy, wx+20, wy+25], fill=(255, 255, 200))

    # Add text overlay with fallback font
    try:
        # Try multiple font paths for different systems
        font_paths = [
            "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf",
            "/System/Library/Fonts/Helvetica.ttc",
            "C:\\Windows\\Fonts\\Arial.ttf"
        ]
        font = None
        for path in font_paths:
            if os.path.exists(path):
                font = ImageFont.truetype(path, 32)
                break
        if font is None:
            font = ImageFont.load_default()
    except Exception:
        font = ImageFont.load_default()

    # Text background
    text_to_display = text[:60] + "..." if len(text) > 60 else text

    # Get text size using textbbox
    bbox = draw.textbbox((0, 0), text_to_display, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]

    text_x = (width - text_width) // 2
    text_y = height - 120

    # Draw semi-transparent rectangle for text background
    draw.rectangle([text_x - 20, text_y - 20, text_x + text_width + 20, text_y + text_height + 20],
                   fill=(0, 0, 0))
    draw.text((text_x, text_y), text_to_display, fill=(255, 255, 255), font=font)

    return img

def create_frame_sequence(img, num_frames=150):
    """Create a sequence of frames with smooth zoom effect"""
    frames = []
    width, height = img.size

    for i in range(num_frames):
        # Calculate zoom factor (1.0 to 1.15)
        zoom = 1.0 + (i / num_frames) * 0.15

        # Calculate new dimensions
        new_width = int(width * zoom)
        new_height = int(height * zoom)

        # Resize image
        zoomed = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # Crop to original size (center crop)
        left = (new_width - width) // 2
        top = (new_height - height) // 2
        frame = zoomed.crop((left, top, left + width, top + height))

        # Convert to numpy array
        frames.append(np.array(frame))

    return frames

def generate_audio(text, filename):
    """Generate audio from text using gTTS"""
    try:
        tts = gTTS(text=text, lang='en', slow=False)
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"Audio generation error: {str(e)}")
        return None

def create_video(scenes):
    """Create video from scenes with audio"""
    all_frames = []
    audio_files = []
    temp_files = []

    try:
        with st.spinner("üé® Generating images and audio..."):
            progress_bar = st.progress(0)

            for idx, scene in enumerate(scenes):
                st.write(f"Processing scene {idx + 1}/3...")

                # Generate image
                img = generate_image_from_text(scene)

                # Create frame sequence (150 frames = 5 seconds at 30fps)
                frames = create_frame_sequence(img, num_frames=150)
                all_frames.extend(frames)

                # Generate audio with proper temp file handling
                audio_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3', mode='wb')
                audio_file.close()
                temp_files.append(audio_file.name)

                audio_path = generate_audio(scene, audio_file.name)
                if audio_path:
                    audio_files.append(audio_path)

                progress_bar.progress((idx + 1) / 3)

        st.success("‚úÖ Images and audio generated!")

        with st.spinner("üé¨ Creating video (this may take a minute)..."):
            # Create video from frames
            clip = ImageSequenceClip(all_frames, fps=30)

            # Load and process audio clips
            audio_clips = []
            current_time = 0

            for i, audio_file in enumerate(audio_files):
                try:
                    audio = AudioFileClip(audio_file)

                    # Adjust audio duration to fit 5 seconds
                    if audio.duration > 5:
                        audio = audio.subclip(0, 5)

                    # Set start time
                    audio = audio.set_start(current_time)
                    audio_clips.append(audio)
                    current_time += 5

                except Exception as e:
                    st.warning(f"Could not load audio for scene {i+1}: {str(e)}")

            # Create composite audio if we have audio clips
            if audio_clips:
                try:
                    final_audio = CompositeAudioClip(audio_clips)
                    clip = clip.set_audio(final_audio)
                except Exception as e:
                    st.warning(f"Could not add audio to video: {str(e)}")

            # Ensure clip is exactly 15 seconds
            clip = clip.set_duration(15)

            # Write video file
            output_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4', mode='wb')
            output_file.close()
            temp_files.append(output_file.name)

            clip.write_videofile(
                output_file.name,
                fps=30,
                codec='libx264',
                audio_codec='aac',
                logger=None,
                preset='ultrafast',
                threads=4
            )

            # Close clips to release resources
            clip.close()
            if audio_clips:
                for audio in audio_clips:
                    audio.close()

            return output_file.name

    except Exception as e:
        st.error(f"Error creating video: {str(e)}")
        # Clean up temp files on error
        for temp_file in temp_files:
            try:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
            except:
                pass
        return None

# Scene inputs
st.markdown("---")
scenes = []

for i in range(3):
    st.markdown(f"### üé• Scene {i+1} (5 seconds)")
    scene = st.text_area(
        f"Describe scene {i+1}",
        placeholder=f"Example: A serene mountain landscape at sunset with golden rays illuminating snow-capped peaks",
        key=f"scene_{i}",
        height=100
    )
    scenes.append(scene)

st.markdown("---")

# Generate button
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    if st.button("üé¨ Generate 15-Second Video", use_container_width=True):
        # Validate inputs
        if any(not scene.strip() for scene in scenes):
            st.error("‚ö†Ô∏è Please fill in all three scene descriptions!")
        else:
            try:
                video_path = create_video(scenes)
                if video_path and os.path.exists(video_path):
                    st.session_state.generated_video = video_path
                    st.success("üéâ Video generated successfully!")
                    st.balloons()
                else:
                    st.error("Failed to generate video. Please try again.")
            except Exception as e:
                st.error(f"‚ùå Error generating video: {str(e)}")

# Display video if generated
if st.session_state.generated_video and os.path.exists(st.session_state.generated_video):
    st.markdown("---")
    st.markdown("### üé¨ Your Generated Video")

    # Display video
    try:
        with open(st.session_state.generated_video, 'rb') as video_file:
            video_bytes = video_file.read()
            st.video(video_bytes)

        # Download button
        st.download_button(
            label="‚¨áÔ∏è Download Video",
            data=video_bytes,
            file_name="ai_generated_video.mp4",
            mime="video/mp4"
        )
    except Exception as e:
        st.error(f"Error displaying video: {str(e)}")

# Info section
st.markdown("---")
st.markdown("""
    <div style='text-align: center; color: white; padding: 20px;'>
        <p>üìä Each scene: 5 seconds ‚Ä¢ 30 FPS ‚Ä¢ 150 frames per scene</p>
        <p>üéµ AI-generated visuals with text-to-speech narration</p>
        <p>üí° Tip: Use descriptive keywords like 'mountain', 'ocean', 'city' for better visuals</p>
    </div>
""", unsafe_allow_html=True)