# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NjCIYfv0WXV76dwqjjSby-jm9Di7y6n_
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from diffusers import StableDiffusionPipeline
# import torch
# from gtts import gTTS
# from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
# from PIL import Image
# import tempfile
# 
# st.title("Text-to-Video Generator")
# 
# scene1 = st.text_input("Scene 1 description", "A futuristic city skyline at sunrise")
# scene2 = st.text_input("Scene 2 description", "A serene forest with a crystal-clear river")
# scene3 = st.text_input("Scene 3 description", "An epic space battle with spaceships")
# 
# if st.button("Generate Video"):
#     prompts = [scene1, scene2, scene3]
# 
#     st.info("Generating images... This may take some time.")
# 
#     # Load diffusion model
#     pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
#     pipe = pipe.to("cuda" if torch.cuda.is_available() else "cpu")
# 
#     images = []
#     audio_files = []
# 
#     for i, prompt in enumerate(prompts):
#         image = pipe(prompt, guidance_scale=7.5).images[0]
#         images.append(image)
# 
#         tts = gTTS(text=prompt, lang='en')
#         audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3").name
#         tts.save(audio_file)
#         audio_files.append(audio_file)
# 
#     st.success("Images and audio generated. Creating video...")
# 
#     scene_clips = []
#     for i, image in enumerate(images):
#         clip = ImageClip(image).set_duration(5)
#         audio = AudioFileClip(audio_files[i])
#         clip = clip.set_audio(audio)
#         scene_clips.append(clip)
# 
#     final_video = concatenate_videoclips(scene_clips)
#     video_file = "final_video.mp4"
#     final_video.write_videofile(video_file, fps=30)
# 
#     st.video(video_file)
#     st.success("Video generated successfully!")

# If running in Colab, uncomment the following:
!pip install diffusers torch moviepy gTTS streamlit Pillow

import streamlit as st
from diffusers import StableDiffusionPipeline
import torch
from gtts import gTTS
from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
import tempfile
import os
from PIL import Image

st.title("Text-to-Video Generator")
st.write("Enter descriptions for 3 scenes. Each scene will last 5 seconds.")

scene1 = st.text_input("Scene 1")
scene2 = st.text_input("Scene 2")
scene3 = st.text_input("Scene 3")

if st.button("Generate Video"):
    prompts = [scene1, scene2, scene3]

    if not all(prompts):
        st.error("Please enter all 3 scene descriptions.")
    else:
        st.info("Generating video... This may take a few minutes.")

# Load Stable Diffusion model (CPU-friendly if using Streamlit Cloud)
@st.cache_resource
def load_model():
    # Use smaller model for CPU if needed
    model_id = "runwayml/stable-diffusion-v1-5"
    pipe = StableDiffusionPipeline.from_pretrained(model_id)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    pipe = pipe.to(device)
    return pipe

pipe = load_model()
st.success("Model loaded!")

images = []

for i, prompt in enumerate(prompts):
    st.write(f"Generating image for Scene {i+1}...")
    image = pipe(prompt, guidance_scale=7.5).images[0]
    images.append(image)
    st.image(image, caption=f"Scene {i+1}", use_column_width=True)

audio_files = []
temp_audio_dir = tempfile.mkdtemp()

for i, text in enumerate(prompts):
    tts = gTTS(text=text, lang='en')
    audio_path = os.path.join(temp_audio_dir, f"scene_{i+1}.mp3")
    tts.save(audio_path)
    audio_files.append(audio_path)
    st.write(f"Audio for Scene {i+1} saved.")

scene_clips = []

for i, image in enumerate(images):
    clip = ImageClip(image).set_duration(5)  # 5 seconds per scene
    audio = AudioFileClip(audio_files[i])
    clip = clip.set_audio(audio)
    scene_clips.append(clip)

final_video = concatenate_videoclips(scene_clips)

temp_video_file = os.path.join(temp_audio_dir, "final_video.mp4")
final_video.write_videofile(temp_video_file, fps=30)
st.success("Video generated!")

st.video(temp_video_file)
st.download_button(
    label="Download Video",
    data=open(temp_video_file, "rb"),
    file_name="text2video.mp4",
    mime="video/mp4"
)